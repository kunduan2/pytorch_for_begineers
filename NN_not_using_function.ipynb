{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import torch\nimport torchvision\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms, datasets\n","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Step 1: Data processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = datasets.MNIST(\"\", train=True, download=True,\n                      transform=transforms.Compose([transforms.ToTensor()]))\ntest = datasets.MNIST(\"\", train=False, download=True,\n                      transform=transforms.Compose([transforms.ToTensor()]))","execution_count":4,"outputs":[{"output_type":"stream","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST/raw/train-images-idx3-ubyte.gz\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed343c486cf9456ca70abc10487a767e"}},"metadata":{}},{"output_type":"stream","text":"Extracting MNIST/raw/train-images-idx3-ubyte.gz to MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST/raw/train-labels-idx1-ubyte.gz\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a1806da06464d06a6e9c598f2a356ec"}},"metadata":{}},{"output_type":"stream","text":"Extracting MNIST/raw/train-labels-idx1-ubyte.gz to MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST/raw/t10k-images-idx3-ubyte.gz\n\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecf9fd5a238a4c27adefa38af5b2848e"}},"metadata":{}},{"output_type":"stream","text":"Extracting MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST/raw/t10k-labels-idx1-ubyte.gz\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0706bd07b5c41048ab1478aaae12c03"}},"metadata":{}},{"output_type":"stream","text":"Extracting MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST/raw\nProcessing...\nDone!\n","name":"stdout"},{"output_type":"stream","text":"/pytorch/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainset = torch.utils.data.DataLoader(train, batch_size=15, shuffle=True)\ntestset = torch.utils.data.DataLoader(train, batch_size=15, shuffle=True)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for data in trainset:\n    data\n#     print(data)\n    break","execution_count":6,"outputs":[{"output_type":"stream","text":"\n\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Note that the randomly shuffled \"data\" is in the form of list with 2 elements where each element is a tensor\nlen(data)","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"2"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[0][0];\n","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[0].shape, data[0][0].shape","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"(torch.Size([15, 1, 28, 28]), torch.Size([1, 28, 28]))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data[1])\nprint(data[1][0])\ndata[1].shape, data[1][0].shape","execution_count":10,"outputs":[{"output_type":"stream","text":"tensor([3, 0, 3, 3, 0, 5, 0, 0, 6, 3, 8, 1, 8, 4, 3])\ntensor(3)\n","name":"stdout"},{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"(torch.Size([15]), torch.Size([]))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# see the data. Note the view command below. it is similar to reshape\nimport matplotlib.pyplot as plt\n\nplt.imshow(data[0][8].view(28,28))\nplt.show()","execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reshape the data\ndata[0].shape","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"torch.Size([15, 1, 28, 28])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Next we check how many of each digits in the train set"},{"metadata":{"trusted":true},"cell_type":"code","source":"def digit_counter(trainset = trainset):\n    total = 0\n    counter_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n    for data in trainset:\n        x_data, y_data = data\n        for y in y_data:\n            counter_dict[int(y)] += 1\n            total += 1\n    print(\"The number of each digits in train set \", counter_dict, \"\\n\")\n    print(\"The total number of digits in train set \", total, \"\\n\")\n    counter_dict_percentage = counter_dict\n    for j in counter_dict_percentage:\n        counter_dict_percentage[j] = (counter_dict_percentage[j]/total)*100\n        counter_dict_percentage[j] = round(counter_dict_percentage[j], 0)  # upto one significant digit\n    counter_dict_percentage\n    print(\"The % of each digits in train set \\n\")\n    return  counter_dict_percentage\ndigit_counter()","execution_count":13,"outputs":[{"output_type":"stream","text":"The number of each digits in train set  {0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949} \n\nThe total number of digits in train set  60000 \n\nThe % of each digits in train set \n\n","name":"stdout"},{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"{0: 10.0,\n 1: 11.0,\n 2: 10.0,\n 3: 10.0,\n 4: 10.0,\n 5: 9.0,\n 6: 10.0,\n 7: 10.0,\n 8: 10.0,\n 9: 10.0}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Step-2: NN"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class NN(nn.Module):\n    def __init__(self, n_input, n_fc1, n_fc2, n_fc3, n_fc4 ):\n        super().__init__()\n        \n        # layer 1\n        self.fc1 = nn.Linear(n_input, n_fc1)\n                \n        # layer 2\n        self.fc2 = nn.Linear(n_fc1, n_fc2)\n                \n        # layer 3\n        self.fc3 = nn.Linear(n_fc2, n_fc3)\n                \n         # layer 4 (output)\n        self.fc4= nn.Linear(n_fc3, n_fc4)\n                \n    def forward(self, X):\n        # layer 1\n        X = self.fc1(X)\n        X = F.relu(X)\n        \n         # layer 2\n        X = self.fc2(X)\n        X = F.relu(X)\n        \n         # layer 3\n        X = self.fc3(X)\n        X = F.relu(X)\n        \n         # layer 4\n        X = self.fc4(X)\n        X = F.log_softmax(X, dim=1)\n        return X\n        \n        ","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = NN(n_input=28*28, n_fc1=64, n_fc2=50, n_fc3=20, n_fc4=10)\nprint(model)","execution_count":16,"outputs":[{"output_type":"stream","text":"NN(\n  (fc1): Linear(in_features=784, out_features=64, bias=True)\n  (fc2): Linear(in_features=64, out_features=50, bias=True)\n  (fc3): Linear(in_features=50, out_features=20, bias=True)\n  (fc4): Linear(in_features=20, out_features=10, bias=True)\n)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = torch.randn((28,28))\nX = X.view(-1, 28*28)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yhat = model(X)\nyhat","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"tensor([[-2.3905, -2.3810, -2.4859, -2.3455, -2.2099, -2.0984, -2.1136, -2.4437,\n         -2.2871, -2.3503]], grad_fn=<LogSoftmaxBackward>)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Step-3: Train model"},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_function = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.01)","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for epoch in range(3):\n    for data in trainset:\n        X, y = data\n        X = X.view(-1, 28*28)\n        # sets gradients = 0 before loss calc. You will do this likely every step.\n        model.zero_grad()\n        yhat = model(X)\n        loss = F.nll_loss(yhat, y)\n    #     print(loss)\n        loss.backward()\n        optimizer.step()\n    print(loss)","execution_count":20,"outputs":[{"output_type":"stream","text":"tensor(0.7344, grad_fn=<NllLossBackward>)\ntensor(0.2590, grad_fn=<NllLossBackward>)\ntensor(0.0220, grad_fn=<NllLossBackward>)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Check the dimensions:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X.shape)\nprint(y.shape)\nprint(yhat.shape)","execution_count":21,"outputs":[{"output_type":"stream","text":"torch.Size([15, 784])\ntorch.Size([15])\ntorch.Size([15, 10])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"correct = 0\ntotal = 0 \n\nwith torch.no_grad():\n    for idx, i in enumerate(yhat):\n        if torch.argmax(i) == y[idx]:\n            correct += 1\n        total += 1\nacc = (correct/total) *100\nprint(\"Accuracy is \", acc)\n        ","execution_count":28,"outputs":[{"output_type":"stream","text":"Accuracy is  100.0\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"* Check how acurate is our model in real sense"},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":35,"outputs":[{"output_type":"execute_result","execution_count":35,"data":{"text/plain":"torch.Size([15, 784])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.imshow(X[0].view(28,28))\nplt.show()","execution_count":36,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.argmax(yhat[0])","execution_count":38,"outputs":[{"output_type":"execute_result","execution_count":38,"data":{"text/plain":"tensor([ -3.1606,  -4.0446,  -3.8586,  -8.2524,  -2.5267,  -5.6209,  -0.1803,\n        -27.9875,  -8.8060, -11.3941], grad_fn=<SelectBackward>)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# idx is basicaaly the first argument in the itensor \n# argmax -> indices correspondiong to the max value along a particular direction (dims)\n\nfor idx, i in enumerate(yhat):\n        # print(torch.argmax(i), y[idx])\n        # print(torch.argmax(i),i, \"\\n\", y[idx], \"\\n\")\n#         if torch.argmax(i) == y[idx]:\n#             correct += 1\n#         total += 1","execution_count":27,"outputs":[{"output_type":"stream","text":"tensor(6, grad_fn=<NotImplemented>) tensor([ -3.1606,  -4.0446,  -3.8586,  -8.2524,  -2.5267,  -5.6209,  -0.1803,\n        -27.9875,  -8.8060, -11.3941], grad_fn=<SelectBackward>) \n tensor(6) \n\ntensor(2, grad_fn=<NotImplemented>) tensor([ -51.1431,  -37.2231,    0.0000,  -35.9422,  -43.3590,  -68.8526,\n         -61.0899, -111.7705,  -63.7852, -140.4282], grad_fn=<SelectBackward>) \n tensor(2) \n\ntensor(7, grad_fn=<NotImplemented>) tensor([-3.4577e+01, -2.2762e+01, -2.6146e+01, -2.3206e+01, -3.6024e+01,\n        -2.4605e+01, -5.8077e+01, -1.1921e-07, -3.9013e+01, -1.5908e+01],\n       grad_fn=<SelectBackward>) \n tensor(7) \n\ntensor(5, grad_fn=<NotImplemented>) tensor([-1.0820e+01, -1.7584e+01, -1.2208e+01, -7.7937e+00, -1.6893e+01,\n        -7.7909e-04, -1.0596e+01, -1.5557e+01, -8.4250e+00, -9.2417e+00],\n       grad_fn=<SelectBackward>) \n tensor(5) \n\ntensor(8, grad_fn=<NotImplemented>) tensor([-1.3683e+01, -9.3415e+00, -1.7309e+01, -1.2978e+01, -1.7405e+01,\n        -1.3190e+01, -1.5887e+01, -1.9055e+01, -2.3124e-04, -8.8880e+00],\n       grad_fn=<SelectBackward>) \n tensor(8) \n\ntensor(7, grad_fn=<NotImplemented>) tensor([ -8.9375,  -4.7270,  -4.0444,  -4.7700,  -8.6345,  -5.8919, -12.8892,\n         -0.0519,  -7.9222,  -4.3983], grad_fn=<SelectBackward>) \n tensor(7) \n\ntensor(7, grad_fn=<NotImplemented>) tensor([-2.1247e+01, -1.6263e+01, -1.9807e+01, -1.7378e+01, -2.3501e+01,\n        -1.6392e+01, -3.9802e+01, -9.8224e-05, -2.7435e+01, -9.2297e+00],\n       grad_fn=<SelectBackward>) \n tensor(7) \n\ntensor(1, grad_fn=<NotImplemented>) tensor([-4.7607e+01, -7.8556e-05, -1.9975e+01, -2.8115e+01, -1.4926e+01,\n        -2.9986e+01, -1.2646e+01, -9.4977e+00, -2.0646e+01, -2.6260e+01],\n       grad_fn=<SelectBackward>) \n tensor(1) \n\ntensor(9, grad_fn=<NotImplemented>) tensor([-2.1972e+01, -1.1986e+01, -1.5762e+01, -9.5320e+00, -9.9106e+00,\n        -1.0692e+01, -2.4494e+01, -9.4947e+00, -1.2546e+01, -2.3005e-04],\n       grad_fn=<SelectBackward>) \n tensor(9) \n\ntensor(1, grad_fn=<NotImplemented>) tensor([-4.0307e+01, -1.2230e-04, -1.8964e+01, -2.4740e+01, -1.2880e+01,\n        -2.5727e+01, -1.1466e+01, -9.1225e+00, -1.6331e+01, -2.1639e+01],\n       grad_fn=<SelectBackward>) \n tensor(1) \n\ntensor(9, grad_fn=<NotImplemented>) tensor([-13.4301,  -7.6754,  -9.9868,  -9.6012,  -3.6365, -10.0019, -14.2740,\n         -7.1731,  -8.2022,  -0.0284], grad_fn=<SelectBackward>) \n tensor(9) \n\ntensor(4, grad_fn=<NotImplemented>) tensor([-1.9384e+01, -1.3784e+01, -1.3246e+01, -1.9844e+01, -1.1482e-03,\n        -1.4956e+01, -1.4324e+01, -1.2778e+01, -1.3827e+01, -6.7768e+00],\n       grad_fn=<SelectBackward>) \n tensor(4) \n\ntensor(8, grad_fn=<NotImplemented>) tensor([-1.4152e+01, -1.4112e+01, -2.0694e+01, -1.6593e+01, -2.3999e+01,\n        -1.7350e+01, -2.0635e+01, -2.6028e+01, -5.2452e-06, -1.2524e+01],\n       grad_fn=<SelectBackward>) \n tensor(8) \n\ntensor(8, grad_fn=<NotImplemented>) tensor([-5.5039, -5.2935, -6.2677, -4.3661, -8.1581, -4.7346, -7.4887, -8.7868,\n        -0.0662, -3.4867], grad_fn=<SelectBackward>) \n tensor(8) \n\ntensor(7, grad_fn=<NotImplemented>) tensor([-2.8501e+01, -1.7115e+01, -1.8514e+01, -1.7093e+01, -2.8684e+01,\n        -1.9474e+01, -4.4933e+01, -1.4305e-06, -2.9503e+01, -1.3490e+01],\n       grad_fn=<SelectBackward>) \n tensor(7) \n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.manual_seed(42)\nn = torch.randn(3,5)\nprint(n)\n# with torch.no_grad():\nfor idx, i in enumerate(n):\n    # print(idx, i, \"\\n\")\n    print(torch.argmax(i))\n    \n#     break","execution_count":24,"outputs":[{"output_type":"stream","text":"tensor([[ 0.3367,  0.1288,  0.2345,  0.2303, -1.1229],\n        [-0.1863,  2.2082, -0.6380,  0.4617,  0.2674],\n        [ 0.5349,  0.8094,  1.1103, -1.6898, -0.9890]])\ntensor(0)\ntensor(1)\ntensor(2)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x in range(10):\n    print(x)\n    break","execution_count":25,"outputs":[{"output_type":"stream","text":"0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"x","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"0"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}